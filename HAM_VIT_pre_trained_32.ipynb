{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyrFAaQYsRk0",
        "outputId": "06b84607-5bd2-4ded-d149-384a04fcecfb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RsIFK_r6HyL9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import os\n",
        "import PIL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "])\n",
        "\n",
        "# Load dataset (Example: ImageNet or Custom)\n",
        "dataset = datasets.ImageFolder(root=\"/content/drive/MyDrive/data_HAM/train\",transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=128, shuffle=True,num_workers=8)\n",
        "\n",
        "# Fetch a batch\n",
        "images, labels = next(iter(dataloader))\n",
        "print(images.shape, labels.shape)  # Should print: (batch_size, 3, 224, 224)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFzqlF3ZIIpL",
        "outputId": "21d0cb6b-2878-4c1c-83cc-c6bba1037076"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 3, 224, 224]) torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "])\n",
        "\n",
        "# Load dataset (Example: ImageNet or Custom)\n",
        "dataset = datasets.ImageFolder(root=\"/content/drive/MyDrive/data_HAM/val\",transform=transform)\n",
        "val_dataloader = DataLoader(dataset, batch_size=128, shuffle=True,num_workers=8)\n",
        "\n",
        "# Fetch a batch\n",
        "images, labels = next(iter(dataloader))\n",
        "print(images.shape, labels.shape)  # Should print: (batch_size, 3, 224, 224)\n"
      ],
      "metadata": {
        "id": "XnD3lMIS8lzU",
        "outputId": "48310abc-c637-49df-e49a-694ad2fb9818",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 3, 224, 224]) torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsLeszttssjQ",
        "outputId": "110f345a-466a-4eb1-a35a-396e754fecb3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.optim as optim  # Import optimizer\n",
        "\n",
        "# Load a pre-trained ViT model\n",
        "model = timm.create_model(\"vit_base_patch32_224\", pretrained=True)\n",
        "\n",
        "# Modify classifier if needed (replace your_num_classes)\n",
        "model.head = torch.nn.Linear(in_features=model.head.in_features, out_features=7)"
      ],
      "metadata": {
        "id": "YClpM--2K66T"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Freeze early layers (optional)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model.head.parameters():  # Unfreeze the classifier head\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adjust learning rate\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "# ... (similar to your existing training loop)"
      ],
      "metadata": {
        "id": "9sYiyXXqfMMS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "0KKVEV9Zve6L",
        "outputId": "8a1e7f26-64af-47a3-ae3a-0bc7acb1d994",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    # Training loop\n",
        "    model.train()  # Set model to training mode\n",
        "    train_loss = 0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(tqdm(dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs} - Training\")):\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Move the model to the device before the forward pass\n",
        "        model.to(device)  # This line is added to move the model to the GPU\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = output.max(1)\n",
        "        total_train += target.size(0)\n",
        "        correct_train += predicted.eq(target).sum().item()\n",
        "\n",
        "    train_accuracy = 100. * correct_train / total_train\n",
        "\n",
        "    # Validation loop (assuming you have a separate validation dataloader)\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    val_loss = 0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(tqdm(val_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs} - Validation\")):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = output.max(1)\n",
        "            total_val += target.size(0)\n",
        "            correct_val += predicted.eq(target).sum().item()\n",
        "\n",
        "    val_accuracy = 100. * correct_val / total_val\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}:\")\n",
        "    print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%\")\n",
        "    print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvgWv4V9dRUM",
        "outputId": "07982ad8-cc65-4b93-e0ef-68d1bd103df8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5 - Training: 100%|██████████| 63/63 [01:05<00:00,  1.05s/it]\n",
            "Epoch 1/5 - Validation: 100%|██████████| 16/16 [00:18<00:00,  1.14s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5:\n",
            "  Train Loss: 39.0128, Train Acc: 77.22%\n",
            "  Val Loss: 10.8373, Val Acc: 74.86%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5 - Training: 100%|██████████| 63/63 [01:04<00:00,  1.02s/it]\n",
            "Epoch 2/5 - Validation: 100%|██████████| 16/16 [00:18<00:00,  1.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5:\n",
            "  Train Loss: 37.0367, Train Acc: 78.51%\n",
            "  Val Loss: 10.5281, Val Acc: 75.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5 - Training: 100%|██████████| 63/63 [01:01<00:00,  1.03it/s]\n",
            "Epoch 3/5 - Validation: 100%|██████████| 16/16 [00:18<00:00,  1.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5:\n",
            "  Train Loss: 35.3327, Train Acc: 79.75%\n",
            "  Val Loss: 10.7085, Val Acc: 74.86%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5 - Training: 100%|██████████| 63/63 [01:01<00:00,  1.03it/s]\n",
            "Epoch 4/5 - Validation: 100%|██████████| 16/16 [00:18<00:00,  1.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5:\n",
            "  Train Loss: 34.6761, Train Acc: 80.13%\n",
            "  Val Loss: 10.2449, Val Acc: 76.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5 - Training: 100%|██████████| 63/63 [01:02<00:00,  1.00it/s]\n",
            "Epoch 5/5 - Validation: 100%|██████████| 16/16 [00:17<00:00,  1.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5:\n",
            "  Train Loss: 32.9480, Train Acc: 81.16%\n",
            "  Val Loss: 10.0447, Val Acc: 76.65%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names=['class1','class2','class3','class4','class5','class6','class7',]"
      ],
      "metadata": {
        "id": "BK9fSPiUhqlg"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "JdGYhnI75knE"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/data_HAM/val/class6/ISIC_0025898.jpg\"\n",
        "\n",
        "image = Image.open(image_path).convert(\"RGB\") # Ensure the image is in RGB format\n",
        "\n",
        "# Preprocess the image using the torchvision transform you defined earlier\n",
        "image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Move inputs to the device\n",
        "image_tensor = image_tensor.to(device)\n",
        "\n",
        "# Make a prediction\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    outputs = model(image_tensor)\n",
        "\n",
        "    predicted_class_index = outputs.argmax(-1).item()\n",
        "\n",
        "# Get the class names (assuming you have a list of class names)\n",
        "class_names = dataset.classes  # Or replace with your class names\n",
        "\n",
        "# Print the predicted class\n",
        "predicted_class_name = class_names[predicted_class_index]\n",
        "print(f\"Predicted class: {predicted_class_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUR6lN4jhjsH",
        "outputId": "d8fff9ad-abc1-47dd-d707-543e2c5e240e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: class6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "it got around 80 % accuracy which is good but still can be improved by unfreezing some layers and train it accorgingly"
      ],
      "metadata": {
        "id": "e4Oze41a-xNK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KcV0L3zg51c1"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}